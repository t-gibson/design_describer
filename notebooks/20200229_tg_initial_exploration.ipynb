{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Similar Graphic Design Templates\n",
    "\n",
    "# The Aim\n",
    "\n",
    "Several companies are springing up that offer ready-made graphic design templates,\n",
    "in categories such as business cards, invitations and presentations. These kind of templates\n",
    "all similar in a sense, but there is lots of variation between them that makes some\n",
    "likable to one user, and unlikable to another. For example all birthday invitations\n",
    "have similar words on them _\"You're invited to my birthday ... it's on YYYY-MM-DD\"_\n",
    "but there's many different layouts, colours and graphics that make it personalised.\n",
    "\n",
    "With the more templates being created, it is easy to get overwhelmed, close the browser and\n",
    "give up on trying to find one you like. Can this experience be improved? Is it possible\n",
    "to offer up suggestions of what a user may like based on what they click on?\n",
    "Rather than a user clicking through Page 1 up to Page 100, could they go down a rabbit-hole\n",
    "of suggested templates, slowly refining it down until they find the one they want?\n",
    "\n",
    "The aim of this little project is to see if we can offer up similar graphic design templates\n",
    "based on an input template. There has been work done in the past on finding similar songs\n",
    "based on an input song ([link](https://github.com/spotify/annoy)) and on finding similar\n",
    "photographs ([link](https://www.kaggle.com/abhikjha/fastai-hooks-and-image-similarity-search)).\n",
    "Can we extend that same approach to design templates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Method\n",
    "\n",
    "The basic principle that both methods listed above use is to generate a list of numeric values that can describe\n",
    "each object. Finding \"similar\" templates is then about selecting out the templates that have the lowest overall difference\n",
    "between its numeric features and the original object's. Another way to think of this is plotting the object into multi-dimensional space, and selecting out the other objects that are \"closest\" to it.\n",
    "\n",
    "For our project we narrowed down on a specific type of graphic design templates: **invitations**.\n",
    "\n",
    "There are different ways to construct a \"Numeric Feature Generator\" <sup>TM</sup> for invitations.\n",
    "\n",
    "The first is to think about different metrics that would define a graphic design. For example, they could be broken into three categories: the text used, the graphics added and the overall layout. The text might be large/small, sans-serif/script. The graphics might be vector-based/hand-drawn, floral/industrial. The layout might be minimal/crowded. With a set of metrics you could label each of your graphics with that information. It would be hard if you don't have the individual elements available. If you could pull it off, the benefit is that these numbers are very explainable to a person off the street.\n",
    "\n",
    "I didn't have access to this kind of info so had to make do with something else. I tried to let a machine learn the key features of a design and see if it was _good enough_ for finding similar graphics. This approach involves setting a machine to learn the images with the task of trying to classify invitations based on their type: weddings, birthdays, bbqs and graduations. As part of that process, the very last stage before the machine will output it's prediction, it generates a 500-length list of numeric features that it weighs up to make it's final decision. Ignoring it's final prediction, pulling this 500-length vector for each of the invitations would do well as a list of numeric features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "I needed to get a set of images of invitations. A well-worded google search and a web scrape meant I was able to\n",
    "get around 150 images per category (bbq, wedding, birthday, graduation). There's lots of noise in google search so doing something like `\"birthday invitations site:canva.com\"` did the job. The benefit of this is that we get the image labelling for free; all images downloaded in each search can be matched to their category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "- We would want to leverage a pre-trained image model\n",
    "- Train it further on our data.\n",
    "- Since we want to simplify the processing, we want to have a vector output based on a range of metrics.\n",
    "This way we can share the nodes across our outputs. To improve results, if needed,\n",
    "we can separate them out into separate models.\n",
    "- Because the cost to label the data is high, we would want to\n",
    "use semi-supervised learning.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "Colours:\n",
    "\n",
    "- Colour palettes\n",
    "- Total number of colours present\n",
    "- Hue\n",
    "- Saturation\n",
    "- Contrast\n",
    "- Monochrome indicator\n",
    "\n",
    "Layout\n",
    "\n",
    "- White space between elements\n",
    "\n",
    "Text\n",
    "\n",
    "- serifness (sans serif -> serif -> script)\n",
    "- kerning\n",
    "- monospaced\n",
    "\n",
    "Graphics\n",
    "\n",
    "- floralness\n",
    "- busyness\n",
    "- realness (from 0 being a definite vector graphic up to\n",
    "1 being something that looks like a hand-drawn painted/drawn object)\n",
    "\n",
    "Some of these outputs are deterministic and wouldn't need to be fed through the model.\n",
    "We can split the above into those that are aggregations on the image (colour, hue, saturation),\n",
    "and those that are about the semantics of the image. With more fine-tuned data,\n",
    "more and more of this wishlist of features can be found for \"free\". I.e. if we had\n",
    "info on the individual elements of a design, we can have a smaller model that runs just\n",
    "for text, and one for graphics. Without that, we are having to deal with the jpeg output\n",
    "of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to from here\n",
    "\n",
    "- Does well on large layout effect (flower border, large numbers, photo frame). Does not do well with _style_ (fonts, humourous/serious)\n",
    "- Attempt with more data. In a production setting you would imagine a company would run it on _all_ of their designs. There's only so much I can recommend if I only have 400 to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
