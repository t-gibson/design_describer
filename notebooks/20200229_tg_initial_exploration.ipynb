{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Exploration\n",
    "\n",
    "The aim of this project is to create something similar to the \"audio features\"\n",
    "([link](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/))\n",
    "that Spotify has for it's songs, applied to graphic design documents.\n",
    "\n",
    "For Spotify, the audio features form the bedrock of\n",
    "their recommendation data products -- Discover Weekly, Daily Mix, Tastebreakers and others.\n",
    "\n",
    "Several companies are springing up that offer ready-made graphic design templates. In different\n",
    "categories such as business cards, wedding invitations and slideshows. [Canva](https://www.canva.com/)\n",
    "is one of them.\n",
    "\n",
    "To be able to create similar recommendation data products for Canva, we'd need to\n",
    "generate information about these different graphic design templates, so that we can\n",
    "embed user's selections into a feature space. With that in place, finding \"similar\"\n",
    "templates (i.e. *Recommended for you*) would be about finding the nearest templates within\n",
    "this feature space.\n",
    "\n",
    "To start we need to extract a set of data of a range of different graphic design templates.\n",
    "We can focus on one category: **invitations**.\n",
    "\n",
    "<!-- Why menus? With a quick glance it seemed that `menu templates` as a search query on google\n",
    "has less *noisy* data. As in, the templates are images with no cropping required for them.\n",
    "By comparison `invitations` is a messy set of images with lots of processing of the images\n",
    "required. We could jump to a different type if the data isn't working out for us. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Possible places to get data from:\n",
    "\n",
    "- Google search results.\n",
    "- Web scrape graphic design web pages: etsy, canva.\n",
    "\n",
    "We would want to drop off from the data any outliers.\n",
    "To keep our first iteration simple, we want features that are\n",
    "clean renderings of the template, not an image\n",
    "of an already-printed object. This can be done with a well-worded google search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "- We would want to leverage a pre-trained image model\n",
    "- Train it further on our data.\n",
    "- Since we want to simplify the processing, we want to have a vector output based on a range of metrics.\n",
    "This way we can share the nodes across our outputs. To improve results, if needed,\n",
    "we can separate them out into separate models.\n",
    "- Because the cost to label the data is high, we would want to\n",
    "use semi-supervised learning.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "Colours:\n",
    "\n",
    "- Colour palettes\n",
    "- Total number of colours present\n",
    "- Hue\n",
    "- Saturation\n",
    "- Contrast\n",
    "- Monochrome indicator\n",
    "\n",
    "Layout\n",
    "\n",
    "- White space between elements\n",
    "\n",
    "Text\n",
    "\n",
    "- serifness (sans serif -> serif -> script)\n",
    "- kerning\n",
    "- monospaced\n",
    "\n",
    "Graphics\n",
    "\n",
    "- floralness\n",
    "- busyness\n",
    "- realness (from 0 being a definite vector graphic up to\n",
    "1 being something that looks like a hand-drawn painted/drawn object)\n",
    "\n",
    "Some of these outputs are deterministic and wouldn't need to be fed through the model.\n",
    "We can split the above into those that are aggregations on the image (colour, hue, saturation),\n",
    "and those that are about the semantics of the image. With more fine-tuned data,\n",
    "more and more of this wishlist of features can be found for \"free\". I.e. if we had\n",
    "info on the individual elements of a design, we can have a smaller model that runs just\n",
    "for text, and one for graphics. Without that, we are having to deal with the jpeg output\n",
    "of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
